import streamlit as st
import cv2
import mediapipe as mp
import numpy as np
import pandas as pd
from PIL import Image
import tempfile
import time

# Mediapipeã®ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—
mp_pose = mp.solutions.pose
mp_hands = mp.solutions.hands
mp_drawing = mp.solutions.drawing_utils

pose = mp_pose.Pose()
hands = mp_hands.Hands()

# **ã‚µã‚¤ãƒ‰ãƒãƒ¼ã§ãƒ¢ãƒ¼ãƒ‰é¸æŠ**
main_mode = st.sidebar.radio("ğŸ” æ¤œå‡ºãƒ¢ãƒ¼ãƒ‰ã‚’é¸æŠ", ["ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ æ¤œå‡º", "å†™çœŸã‹ã‚‰åº§æ¨™ã‚’æ¤œå‡º", "å‹•ç”»ã‹ã‚‰åº§æ¨™ã‚’æ¤œå‡º"])
sub_mode = st.sidebar.radio("ğŸ“Œ æ¤œå‡ºå¯¾è±¡ã‚’é¸æŠ", ["ä½“ã®é–¢ç¯€ã®ã¿", "æ‰‹ã®é–¢ç¯€ã®ã¿", "ã™ã¹ã¦"])

st.title("ğŸ“Œ éª¨æ ¼æ¤œå‡ºã‚¢ãƒ—ãƒª")

# **ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ æ¤œå‡ºãƒ¢ãƒ¼ãƒ‰**
if main_mode == "ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ æ¤œå‡º":
    st.subheader("ğŸ¥ ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ã§éª¨æ ¼ã‚’æ¤œå‡ºä¸­...")
    cap = cv2.VideoCapture(0)
    if not cap.isOpened():
        st.error("ã‚«ãƒ¡ãƒ©ã‚’é–‹ã‘ã¾ã›ã‚“ã§ã—ãŸã€‚")
    else:
        FRAME_WINDOW = st.empty()
        while True:
            ret, frame = cap.read()
            if not ret:
                st.error("ã‚«ãƒ¡ãƒ©æ˜ åƒã®å–å¾—ã«å¤±æ•—ã—ã¾ã—ãŸã€‚")
                break
            frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
            results_pose = pose.process(frame) if sub_mode in ["ä½“ã®é–¢ç¯€ã®ã¿", "ã™ã¹ã¦"] else None
            results_hands = hands.process(frame) if sub_mode in ["æ‰‹ã®é–¢ç¯€ã®ã¿", "ã™ã¹ã¦"] else None
            if results_pose and results_pose.pose_landmarks:
                mp_drawing.draw_landmarks(frame, results_pose.pose_landmarks, mp_pose.POSE_CONNECTIONS)
            if results_hands and results_hands.multi_hand_landmarks:
                for hand_landmarks in results_hands.multi_hand_landmarks:
                    mp_drawing.draw_landmarks(frame, hand_landmarks, mp_hands.HAND_CONNECTIONS)
            FRAME_WINDOW.image(frame, channels="RGB")
        cap.release()

# **å†™çœŸã‹ã‚‰åº§æ¨™ã‚’æ¤œå‡ºã™ã‚‹ãƒ¢ãƒ¼ãƒ‰**
elif main_mode == "å†™çœŸã‹ã‚‰åº§æ¨™ã‚’æ¤œå‡º":
    st.subheader("ğŸ“¸ å†™çœŸã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„")
    img_file = st.file_uploader("ç”»åƒã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰", type=["jpg", "jpeg", "png"])
    if img_file is not None:
        image = Image.open(img_file)
        frame = np.array(image)
        frame = cv2.cvtColor(frame, cv2.COLOR_RGB2BGR)
        results_pose = pose.process(frame) if sub_mode in ["ä½“ã®é–¢ç¯€ã®ã¿", "ã™ã¹ã¦"] else None
        results_hands = hands.process(frame) if sub_mode in ["æ‰‹ã®é–¢ç¯€ã®ã¿", "ã™ã¹ã¦"] else None
        if results_pose and results_pose.pose_landmarks:
            mp_drawing.draw_landmarks(frame, results_pose.pose_landmarks, mp_pose.POSE_CONNECTIONS)
        if results_hands and results_hands.multi_hand_landmarks:
            for hand_landmarks in results_hands.multi_hand_landmarks:
                mp_drawing.draw_landmarks(frame, hand_landmarks, mp_hands.HAND_CONNECTIONS)
        st.image(frame, channels="BGR", use_column_width=True)

# **å‹•ç”»ã‹ã‚‰åº§æ¨™ã‚’æ¤œå‡ºã™ã‚‹ãƒ¢ãƒ¼ãƒ‰**
elif main_mode == "å‹•ç”»ã‹ã‚‰åº§æ¨™ã‚’æ¤œå‡º":
    st.subheader("ğŸï¸ å‹•ç”»ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„")
    video_file = st.file_uploader("å‹•ç”»ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰", type=["mp4", "mov", "avi"])
    if video_file is not None:
        with tempfile.NamedTemporaryFile(delete=False, suffix=".mp4") as temp_video:
            temp_video.write(video_file.read())
            temp_video_path = temp_video.name
        cap = cv2.VideoCapture(temp_video_path)
        fps = cap.get(cv2.CAP_PROP_FPS)
        delay = 1 / fps if fps > 0 else 0.03  # FPSãŒå–å¾—ã§ããªã„å ´åˆã®ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆé…å»¶
        FRAME_WINDOW = st.empty()
        while cap.isOpened():
            ret, frame = cap.read()
            if not ret:
                break
            frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
            results_pose = pose.process(frame) if sub_mode in ["ä½“ã®é–¢ç¯€ã®ã¿", "ã™ã¹ã¦"] else None
            results_hands = hands.process(frame) if sub_mode in ["æ‰‹ã®é–¢ç¯€ã®ã¿", "ã™ã¹ã¦"] else None
            if results_pose and results_pose.pose_landmarks:
                mp_drawing.draw_landmarks(frame, results_pose.pose_landmarks, mp_pose.POSE_CONNECTIONS)
            if results_hands and results_hands.multi_hand_landmarks:
                for hand_landmarks in results_hands.multi_hand_landmarks:
                    mp_drawing.draw_landmarks(frame, hand_landmarks, mp_hands.HAND_CONNECTIONS)
            FRAME_WINDOW.image(frame, channels="RGB")
            time.sleep(delay)
        cap.release()
        st.success("å‹•ç”»ã®å‡¦ç†ãŒå®Œäº†ã—ã¾ã—ãŸ ğŸ‰")
