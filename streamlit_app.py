import streamlit as st
import cv2
import mediapipe as mp
import numpy as np
import tempfile
import time

# Mediapipeã®ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—
mp_pose = mp.solutions.pose
mp_hands = mp.solutions.hands
mp_drawing = mp.solutions.drawing_utils
pose = mp_pose.Pose()
hands = mp_hands.Hands()

st.title("ğŸ“Œ éª¨æ ¼æ¤œå‡ºã‚¢ãƒ—ãƒª")

# **ã‚µã‚¤ãƒ‰ãƒãƒ¼ã§ãƒ¢ãƒ¼ãƒ‰é¸æŠ**
main_mode = st.sidebar.radio("ğŸ” æ¤œå‡ºãƒ¢ãƒ¼ãƒ‰ã‚’é¸æŠ", ["ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ æ¤œå‡º", "å†™çœŸã‹ã‚‰åº§æ¨™ã‚’æ¤œå‡º", "å‹•ç”»ã‹ã‚‰åº§æ¨™ã‚’æ¤œå‡º"])
sub_mode = st.sidebar.radio("ğŸ“Œ æ¤œå‡ºå¯¾è±¡ã‚’é¸æŠ", ["ä½“ã®é–¢ç¯€ã®ã¿", "æ‰‹ã®é–¢ç¯€ã®ã¿", "ã™ã¹ã¦"])

# **éª¨æ ¼ãƒã‚¤ãƒ³ãƒˆã«æœ€ã‚‚è¿‘ã„ç‚¹ã‚’è¦‹ã¤ã‘ã‚‹é–¢æ•°**
def find_nearest_landmark(mouse_x, mouse_y, landmarks, frame):
    min_dist = float('inf')
    nearest_point = None
    for idx, landmark in enumerate(landmarks):
        x, y = int(landmark.x * frame.shape[1]), int(landmark.y * frame.shape[0])
        dist = np.sqrt((mouse_x - x) ** 2 + (mouse_y - y) ** 2)
        if dist < min_dist:
            min_dist = dist
            nearest_point = (x, y, idx)
    return nearest_point if min_dist < 20 else None  # 20pxä»¥å†…ãªã‚‰è¡¨ç¤º

# **ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ æ¤œå‡ºãƒ¢ãƒ¼ãƒ‰**
if main_mode == "ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ æ¤œå‡º":
    st.subheader("ğŸ¥ ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ã§éª¨æ ¼ã‚’æ¤œå‡ºä¸­...")
    cap = cv2.VideoCapture(0)
    FRAME_WINDOW = st.empty()
    
    while cap.isOpened():
        ret, frame = cap.read()
        if not ret:
            st.error("ã‚«ãƒ¡ãƒ©æ˜ åƒã®å–å¾—ã«å¤±æ•—ã—ã¾ã—ãŸã€‚")
            break
        frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
        results_pose = pose.process(frame) if sub_mode in ["ä½“ã®é–¢ç¯€ã®ã¿", "ã™ã¹ã¦"] else None
        results_hands = hands.process(frame) if sub_mode in ["æ‰‹ã®é–¢ç¯€ã®ã¿", "ã™ã¹ã¦"] else None
        
        if results_pose and results_pose.pose_landmarks:
            mp_drawing.draw_landmarks(frame, results_pose.pose_landmarks, mp_pose.POSE_CONNECTIONS)
        if results_hands and results_hands.multi_hand_landmarks:
            for hand_landmarks in results_hands.multi_hand_landmarks:
                mp_drawing.draw_landmarks(frame, hand_landmarks, mp_hands.HAND_CONNECTIONS)
        
        FRAME_WINDOW.image(frame, channels="RGB")
    cap.release()

# **å†™çœŸã‹ã‚‰åº§æ¨™ã‚’æ¤œå‡ºã™ã‚‹ãƒ¢ãƒ¼ãƒ‰**
elif main_mode == "å†™çœŸã‹ã‚‰åº§æ¨™ã‚’æ¤œå‡º":
    st.subheader("ğŸ“¸ å†™çœŸã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„")
    img_file = st.file_uploader("ç”»åƒã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰", type=["jpg", "jpeg", "png"])
    if img_file is not None:
        image = np.array(cv2.imdecode(np.frombuffer(img_file.read(), np.uint8), 1))
        results_pose = pose.process(image) if sub_mode in ["ä½“ã®é–¢ç¯€ã®ã¿", "ã™ã¹ã¦"] else None
        results_hands = hands.process(image) if sub_mode in ["æ‰‹ã®é–¢ç¯€ã®ã¿", "ã™ã¹ã¦"] else None
        
        if results_pose and results_pose.pose_landmarks:
            mp_drawing.draw_landmarks(image, results_pose.pose_landmarks, mp_pose.POSE_CONNECTIONS)
        if results_hands and results_hands.multi_hand_landmarks:
            for hand_landmarks in results_hands.multi_hand_landmarks:
                mp_drawing.draw_landmarks(image, hand_landmarks, mp_hands.HAND_CONNECTIONS)
        
        st.image(image, channels="BGR", use_column_width=True)

# **å‹•ç”»ã‹ã‚‰åº§æ¨™ã‚’æ¤œå‡ºã™ã‚‹ãƒ¢ãƒ¼ãƒ‰**
elif main_mode == "å‹•ç”»ã‹ã‚‰åº§æ¨™ã‚’æ¤œå‡º":
    st.subheader("ğŸï¸ å‹•ç”»ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„")
    video_file = st.file_uploader("å‹•ç”»ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰", type=["mp4", "mov", "avi"])
    if video_file is not None:
        with tempfile.NamedTemporaryFile(delete=False, suffix=".mp4") as temp_video:
            temp_video.write(video_file.read())
            temp_video_path = temp_video.name
        cap = cv2.VideoCapture(temp_video_path)
        fps = cap.get(cv2.CAP_PROP_FPS)
        delay = 1 / fps if fps > 0 else 0.03
        FRAME_WINDOW = st.empty()
        
        while cap.isOpened():
            ret, frame = cap.read()
            if not ret:
                break
            frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
            results_pose = pose.process(frame) if sub_mode in ["ä½“ã®é–¢ç¯€ã®ã¿", "ã™ã¹ã¦"] else None
            results_hands = hands.process(frame) if sub_mode in ["æ‰‹ã®é–¢ç¯€ã®ã¿", "ã™ã¹ã¦"] else None
            
            if results_pose and results_pose.pose_landmarks:
                mp_drawing.draw_landmarks(frame, results_pose.pose_landmarks, mp_pose.POSE_CONNECTIONS)
            if results_hands and results_hands.multi_hand_landmarks:
                for hand_landmarks in results_hands.multi_hand_landmarks:
                    mp_drawing.draw_landmarks(frame, hand_landmarks, mp_hands.HAND_CONNECTIONS)
            
            FRAME_WINDOW.image(frame, channels="RGB")
            time.sleep(delay)
        cap.release()
        st.success("å‹•ç”»ã®å‡¦ç†ãŒå®Œäº†ã—ã¾ã—ãŸ ğŸ‰")
