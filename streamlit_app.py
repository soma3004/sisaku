import streamlit as st
import mediapipe as mp
import numpy as np
import cv2
from PIL import Image
import pandas as pd

# Mediapipeã®ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚’åˆæœŸåŒ–
mp_pose = mp.solutions.pose
mp_hands = mp.solutions.hands
mp_face_mesh = mp.solutions.face_mesh
mp_drawing = mp.solutions.drawing_utils

# Mediapipeã®ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹
pose = mp_pose.Pose()
hands = mp_hands.Hands()
face_mesh = mp_face_mesh.FaceMesh()

# **ã‚µã‚¤ãƒ‰ãƒãƒ¼ã§ãƒ¢ãƒ¼ãƒ‰é¸æŠ**
mode = st.sidebar.radio("ğŸ” æ¤œå‡ºãƒ¢ãƒ¼ãƒ‰ã‚’é¸æŠ", ["ä½“ã®é–¢ç¯€ã®ã¿", "æ‰‹ã®é–¢ç¯€ã®ã¿", "è¡¨æƒ…ã®ã¿", "ã™ã¹ã¦"])

# **ä½“ã®é–¢ç¯€ã®ã¿ã®ãƒªã‚¹ãƒˆï¼ˆé¡”ã¯é™¤å¤–ï¼‰**
BODY_LANDMARKS = [
    mp_pose.PoseLandmark.LEFT_SHOULDER,
    mp_pose.PoseLandmark.RIGHT_SHOULDER,
    mp_pose.PoseLandmark.LEFT_ELBOW,
    mp_pose.PoseLandmark.RIGHT_ELBOW,
    mp_pose.PoseLandmark.LEFT_WRIST,
    mp_pose.PoseLandmark.RIGHT_WRIST,
    mp_pose.PoseLandmark.LEFT_HIP,
    mp_pose.PoseLandmark.RIGHT_HIP,
    mp_pose.PoseLandmark.LEFT_KNEE,
    mp_pose.PoseLandmark.RIGHT_KNEE,
    mp_pose.PoseLandmark.LEFT_ANKLE,
    mp_pose.PoseLandmark.RIGHT_ANKLE
]

st.title("ğŸ“Œ Pose, Hand, and Face Detection")

# ã‚«ãƒ¡ãƒ©ç”»åƒã‚’å–å¾—
img_file = st.camera_input("ğŸ“· Take a picture")

if img_file is not None:
    # ç”»åƒã‚’PILã‹ã‚‰OpenCVã®å½¢å¼ã«å¤‰æ›
    image = Image.open(img_file)
    frame = np.array(image)

    # OpenCVã¯BGRã€Streamlitã¯RGBã‚’æ‰±ã†ãŸã‚å¤‰æ›
    frame = cv2.cvtColor(frame, cv2.COLOR_RGB2BGR)

    # Mediapipeã§å‡¦ç†
    results_pose = pose.process(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)) if mode in ["ä½“ã®é–¢ç¯€ã®ã¿", "ã™ã¹ã¦"] else None
    results_hands = hands.process(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)) if mode in ["æ‰‹ã®é–¢ç¯€ã®ã¿", "ã™ã¹ã¦"] else None
    results_face = face_mesh.process(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)) if mode in ["è¡¨æƒ…ã®ã¿", "ã™ã¹ã¦"] else None

    # åº§æ¨™ãƒ‡ãƒ¼ã‚¿ã‚’æ ¼ç´ã™ã‚‹ãƒªã‚¹ãƒˆ
    landmarks_list = []

    # **ä½“ã®é–¢ç¯€ã‚’æç”»**
    if results_pose and results_pose.pose_landmarks:
        for landmark_id in BODY_LANDMARKS:
            landmark = results_pose.pose_landmarks.landmark[landmark_id]
            x, y = int(landmark.x * frame.shape[1]), int(landmark.y * frame.shape[0])
            cv2.circle(frame, (x, y), 5, (0, 255, 0), -1)  # ç·‘è‰²ã§æç”»
            landmarks_list.append({"Type": "Body", "Point": landmark_id.name, "X": x, "Y": y})

        # éª¨æ ¼ãƒ©ã‚¤ãƒ³ã‚’æç”»
        mp_drawing.draw_landmarks(frame, results_pose.pose_landmarks, mp_pose.POSE_CONNECTIONS)

    # **æ‰‹ã®é–¢ç¯€ã‚’æç”»**
    if results_hands and results_hands.multi_hand_landmarks:
        for hand_landmarks in results_hands.multi_hand_landmarks:
            for idx, landmark in enumerate(hand_landmarks.landmark):
                x, y = int(landmark.x * frame.shape[1]), int(landmark.y * frame.shape[0])
                cv2.circle(frame, (x, y), 5, (255, 0, 0), -1)  # é’è‰²ã§æç”»
                landmarks_list.append({"Type": "Hand", "Point": f"Hand_{idx}", "X": x, "Y": y})

            # æ‰‹ã®é–¢ç¯€ãƒ©ã‚¤ãƒ³ã‚’æç”»
            mp_drawing.draw_landmarks(frame, hand_landmarks, mp_hands.HAND_CONNECTIONS)

    # **é¡”ã®ãƒ©ãƒ³ãƒ‰ãƒãƒ¼ã‚¯ã‚’æç”»**
    if results_face and results_face.multi_face_landmarks:
        for face_landmarks in results_face.multi_face_landmarks:
            for idx, landmark in enumerate(face_landmarks.landmark):
                x, y = int(landmark.x * frame.shape[1]), int(landmark.y * frame.shape[0])
                cv2.circle(frame, (x, y), 2, (0, 0, 255), -1)  # èµ¤è‰²ã§æç”»
                landmarks_list.append({"Type": "Face", "Point": f"Face_{idx}", "X": x, "Y": y})

            # é¡”ã®ãƒ©ãƒ³ãƒ‰ãƒãƒ¼ã‚¯ãƒ©ã‚¤ãƒ³ã‚’æç”»
            mp_drawing.draw_landmarks(frame, face_landmarks, mp_face_mesh.FACEMESH_TESSELATION)

    # **Streamlitã§ç”»åƒã‚’è¡¨ç¤º**
    st.image(frame, channels="BGR", use_column_width=True)

    # **åº§æ¨™ãƒ‡ãƒ¼ã‚¿ã‚’è¡¨ã§è¡¨ç¤º**
    if landmarks_list:
        df = pd.DataFrame(landmarks_list)
        st.table(df)
