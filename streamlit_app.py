import streamlit as st
import cv2
import mediapipe as mp
import numpy as np
import pandas as pd
from PIL import Image

# Mediapipeã®ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—
mp_pose = mp.solutions.pose
mp_hands = mp.solutions.hands
mp_drawing = mp.solutions.drawing_utils

pose = mp_pose.Pose()
hands = mp_hands.Hands()

# **ã‚µã‚¤ãƒ‰ãƒãƒ¼ã§ãƒ¢ãƒ¼ãƒ‰é¸æŠ**
main_mode = st.sidebar.radio("ğŸ” æ¤œå‡ºãƒ¢ãƒ¼ãƒ‰ã‚’é¸æŠ", ["ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ æ¤œå‡º", "å†™çœŸã‹ã‚‰åº§æ¨™ã‚’æ¤œå‡º"])
sub_mode = st.sidebar.radio("ğŸ“Œ æ¤œå‡ºå¯¾è±¡ã‚’é¸æŠ", ["ä½“ã®é–¢ç¯€ã®ã¿", "æ‰‹ã®é–¢ç¯€ã®ã¿", "ã™ã¹ã¦"])

st.title("ğŸ“Œ éª¨æ ¼æ¤œå‡ºã‚¢ãƒ—ãƒª")

# **ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ æ¤œå‡ºãƒ¢ãƒ¼ãƒ‰**
if main_mode == "ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ æ¤œå‡º":
    st.subheader("ğŸ¥ ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ã§éª¨æ ¼ã‚’æ¤œå‡ºä¸­...")
    cap = cv2.VideoCapture(0)
    FRAME_WINDOW = st.image([])

    while cap.isOpened():
        ret, frame = cap.read()
        if not ret:
            st.error("ã‚«ãƒ¡ãƒ©ã‚’é–‹ã‘ã¾ã›ã‚“ã§ã—ãŸã€‚")
            break

        frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)

        # **Mediapipeã§å‡¦ç†**
        results_pose = pose.process(frame) if sub_mode in ["ä½“ã®é–¢ç¯€ã®ã¿", "ã™ã¹ã¦"] else None
        results_hands = hands.process(frame) if sub_mode in ["æ‰‹ã®é–¢ç¯€ã®ã¿", "ã™ã¹ã¦"] else None

        # **ä½“ã®é–¢ç¯€ã‚’æç”»**
        if results_pose and results_pose.pose_landmarks:
            mp_drawing.draw_landmarks(frame, results_pose.pose_landmarks, mp_pose.POSE_CONNECTIONS)

        # **æ‰‹ã®é–¢ç¯€ã‚’æç”»**
        if results_hands and results_hands.multi_hand_landmarks:
            for hand_landmarks in results_hands.multi_hand_landmarks:
                mp_drawing.draw_landmarks(frame, hand_landmarks, mp_hands.HAND_CONNECTIONS)

        # **æ˜ åƒã‚’æ›´æ–°**
        FRAME_WINDOW.image(frame)

    cap.release()
    cv2.destroyAllWindows()

# **å†™çœŸã‹ã‚‰åº§æ¨™ã‚’æ¤œå‡ºã™ã‚‹ãƒ¢ãƒ¼ãƒ‰**
else:
    st.subheader("ğŸ“¸ å†™çœŸã‚’æ’®å½± or ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„")
    img_file = st.file_uploader("ç”»åƒã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰", type=["jpg", "jpeg", "png"])

    if img_file is not None:
        image = Image.open(img_file)
        frame = np.array(image)
        frame = cv2.cvtColor(frame, cv2.COLOR_RGB2BGR)

        # **Mediapipeã§å‡¦ç†**
        results_pose = pose.process(frame) if sub_mode in ["ä½“ã®é–¢ç¯€ã®ã¿", "ã™ã¹ã¦"] else None
        results_hands = hands.process(frame) if sub_mode in ["æ‰‹ã®é–¢ç¯€ã®ã¿", "ã™ã¹ã¦"] else None

        landmarks_list = []

        # **ä½“ã®é–¢ç¯€ã‚’æç”»**
        if results_pose and results_pose.pose_landmarks:
            for idx, landmark in enumerate(results_pose.pose_landmarks.landmark):
                x, y = int(landmark.x * frame.shape[1]), int(landmark.y * frame.shape[0])
                landmarks_list.append({"Type": "Body", "Point": f"Joint_{idx}", "X": x, "Y": y})
            mp_drawing.draw_landmarks(frame, results_pose.pose_landmarks, mp_pose.POSE_CONNECTIONS)

        # **æ‰‹ã®é–¢ç¯€ã‚’æç”»**
        if results_hands and results_hands.multi_hand_landmarks:
            for hand_landmarks in results_hands.multi_hand_landmarks:
                for idx, landmark in enumerate(hand_landmarks.landmark):
                    x, y = int(landmark.x * frame.shape[1]), int(landmark.y * frame.shape[0])
                    landmarks_list.append({"Type": "Hand", "Point": f"Hand_{idx}", "X": x, "Y": y})
                mp_drawing.draw_landmarks(frame, hand_landmarks, mp_hands.HAND_CONNECTIONS)

        # **ç”»åƒã‚’è¡¨ç¤º**
        st.image(frame, channels="BGR", use_column_width=True)

        # **åº§æ¨™ãƒ‡ãƒ¼ã‚¿ã‚’è¡¨ã§è¡¨ç¤º**
        if landmarks_list:
            df = pd.DataFrame(landmarks_list)
            st.table(df)
