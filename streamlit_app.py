import streamlit as st
import numpy as np
import cv2
import av
import mediapipe as mp
from streamlit_webrtc import webrtc_streamer, VideoProcessorBase

# === Mediapipe ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ— ===
mp_pose = mp.solutions.pose
mp_hands = mp.solutions.hands
mp_drawing = mp.solutions.drawing_utils

pose = mp_pose.Pose()
hands = mp_hands.Hands()

# === ã‚µã‚¤ãƒ‰ãƒãƒ¼ã§ãƒ¢ãƒ¼ãƒ‰é¸æŠ ===
mode = st.sidebar.radio("ğŸ“Œ ãƒ¢ãƒ¼ãƒ‰é¸æŠ", ["ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ æ¤œå‡º (PC)", "ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ æ¤œå‡º (ã‚¹ãƒãƒ›)", "å†™çœŸã‹ã‚‰æ¤œå‡º"])
sub_mode = st.sidebar.radio("ğŸ“Œ æ¤œå‡ºå¯¾è±¡", ["ä½“ã®é–¢ç¯€ã®ã¿", "æ‰‹ã®é–¢ç¯€ã®ã¿", "ã™ã¹ã¦"])

st.title("ğŸ“Œ PC & ã‚¹ãƒãƒ›å¯¾å¿œ éª¨æ ¼æ¤œå‡ºã‚¢ãƒ—ãƒª")

# === ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ æ¤œå‡º (ã‚¹ãƒãƒ› & PCå…±é€šå‡¦ç†) ===
def process_frame(img):
    """Mediapipe ã§éª¨æ ¼ãƒ»æ‰‹ã®é–¢ç¯€ã‚’æ¤œå‡º"""
    results_pose = pose.process(img) if sub_mode in ["ä½“ã®é–¢ç¯€ã®ã¿", "ã™ã¹ã¦"] else None
    results_hands = hands.process(img) if sub_mode in ["æ‰‹ã®é–¢ç¯€ã®ã¿", "ã™ã¹ã¦"] else None

    if results_pose and results_pose.pose_landmarks:
        mp_drawing.draw_landmarks(img, results_pose.pose_landmarks, mp_pose.POSE_CONNECTIONS)

    if results_hands and results_hands.multi_hand_landmarks:
        for hand_landmarks in results_hands.multi_hand_landmarks:
            mp_drawing.draw_landmarks(img, hand_landmarks, mp_hands.HAND_CONNECTIONS)

    return img

# === ãƒ¢ãƒ¼ãƒ‰â‘ : PCã®Webã‚«ãƒ¡ãƒ©ã§ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ æ¤œå‡º ===
if mode == "ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ æ¤œå‡º (PC)":
    st.write("ğŸ’» PCã®Webã‚«ãƒ¡ãƒ©ã‚’ä½¿ç”¨ã—ã¾ã™")

    cap = cv2.VideoCapture(0)

    if not cap.isOpened():
        st.error("ã‚«ãƒ¡ãƒ©ã‚’é–‹ã‘ã¾ã›ã‚“ã§ã—ãŸã€‚åˆ¥ã®ã‚¢ãƒ—ãƒªãŒä½¿ç”¨ã—ã¦ã„ã¾ã›ã‚“ã‹ï¼Ÿ")
    else:
        stframe = st.empty()
        while cap.isOpened():
            ret, frame = cap.read()
            if not ret:
                st.error("ã‚«ãƒ¡ãƒ©ã‹ã‚‰æ˜ åƒã‚’å–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸ")
                break

            frame = process_frame(frame)
            frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
            stframe.image(frame, channels="RGB")

        cap.release()

# === ãƒ¢ãƒ¼ãƒ‰â‘¡: ã‚¹ãƒãƒ›ã®ã‚«ãƒ¡ãƒ©ã§ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ æ¤œå‡º ===
elif mode == "ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ æ¤œå‡º (ã‚¹ãƒãƒ›)":
    st.write("ğŸ“± ã‚¹ãƒãƒ›ã®ã‚«ãƒ¡ãƒ©ã‚’ä½¿ç”¨ã—ã¾ã™")

    class VideoProcessor(VideoProcessorBase):
        def recv(self, frame):
            img = frame.to_ndarray(format="bgr24")
            img = process_frame(img)
            return av.VideoFrame.from_ndarray(img, format="bgr24")

    webrtc_streamer(key="example", video_processor_factory=VideoProcessor)

# === ãƒ¢ãƒ¼ãƒ‰â‘¢: ç”»åƒã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦éª¨æ ¼æ¤œå‡º ===
elif mode == "å†™çœŸã‹ã‚‰æ¤œå‡º":
    st.write("ğŸ–¼ å†™çœŸã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦æ¤œå‡ºã—ã¾ã™")

    uploaded_file = st.file_uploader("ç”»åƒã‚’é¸æŠ", type=["jpg", "png", "jpeg"])
    
    if uploaded_file:
        file_bytes = np.asarray(bytearray(uploaded_file.read()), dtype=np.uint8)
        img = cv2.imdecode(file_bytes, 1)

        img = process_frame(img)
        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
        
        st.image(img, channels="RGB", caption="æ¤œå‡ºçµæœ")
